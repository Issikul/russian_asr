%----------------------------------------------------------------------------
\chapter{Tervezés}
%----------------------------------------------------------------------------

\section{Tervezés, döntési lehetőségek értékelése}

\subsection{Fejlesztési nyelv}

A Python napjaink egyik legelterjedtebb programozási nyelve. Egy könnyen programozható és átlátható, interpretált nyelv, melyben a megírt program kódot a Python értelmező sorról-sorra értelmezi és futtatja, nincs különválasztva a forrás és a fordított kód. Deep learning körökben is dominál a Python nyelv, rengeteg deep learning toolkit erre a nyelvre épít, így választásom a fejlesztéshez természetesen a Python nyelvre esett.

\subsection{NeMo}

A neurális hálók komplikáltságából adódik, hogy pontos és precíz implementációjuk igen bonyolult és időigényes. Emiatt célszerű a már meglévő, bejáratott és bizonyított lehetőségeket használni, így felgyorsítva a fejlesztési folyamatot és javítva a potenciálisan elért eredményeket. Több deep learing platform is található az internetet, mint például a Tensorflow vagy PyTorch. Az Nvidia által fejlesztett NeMo\footnote{NeMo toolkit, \url{https://github.com/NVIDIA/NeMo}} egy olyan összetett és folyamatosan karbantartott toolkit, melynek segítségével különböző mesterséges intelligencia alapú társalgási, beszéddel kapcsolatos applikációkat, alkalmazásokat készíthetünk. Munkám során ennek fényében a NeMo toolkit-et használtam.

Az alapkoncepcióját a toolkit-nek az úgynevezett Neurális Modulok alkotják. Ezek a modulok lehetnek például adat rétegek, kódolók, dekóderek, nyelvmodellek vagy loss függvények. A modulok ereje abban rejlik hogy egymáshoz viszonyítva tetszőlegesen építhetők, cserélhetők, törölhetők. Egy egyszerű módosítással kicserélhető például a loss számításához használt függvény anélkül, hogy a kódot a többi modulban módosítani kéne.

Az 3.1-es táblán látható modellek közül az Nvidia fejlesztette a legkevésbé számításigényeset, mely figyelemreméltó eredményeket produkál. Ez a QuartzNet modell, ami az alacsony paraméterszáma ellenére SOTA eredményeket ér el. A felsorolt okokból kifolyólag a fejlesztési folyamat elvégzéséhez választásom a NeMo toolkit-re esett, melyenek 1.0.0b verziójával dolgoztam.

\subsubsection{PyTorch}

A NeMo a PyTorch nevű, Facebook-os kutatók által fejlesztett, mesterséges intelligencia fejlesztésére szakosodott nyílt forráskódú keretrendszerre épít. A PyTorch a TensorFlow-nál magasabb szintű, könnyebben kezelhető keretrendszer, mely egyre inkább elterjedtté válik a kutatók és fejlesztők körében. A NeMo működéséhez 1.6+ verzió szükséges, én az 1.6-os verziót alkalmaztam.

\subsubsection{QuartzNet}

A kísérleteimet QuartzNet architektúrájú modellekkel elvégeztem, a korábban említett alacsony paraméterszáma és magas precizitása végett. Az architektúra (4.1-es ábra) nagyban hasonlít egy másik Nvidia által fejlesztett architektúrához, a Jasper-hez. A modell B darab blokkból áll. Egy opcionálisan beállítható dropout modul is megjelenhet a modellben, illetve CTC loss függvény számítás található benne. A már említett blokkok további, R darab blokkból állnak, melyek konvolúciós rétegekből, batch normalizálókból és ReLU aktivációs függvényből épülnek fel. Ezáltal a QuartzNet pontos felépítésére QuartzNet BxR alakban szokás hivatkozni. A legnagyobb Nvidia által készített a Quartznet 15x5, mely 18.9 millió paraméterből áll, amit kiterjedten használtam a  kísérleteim során.

A QuartzNet a Jasper-től a konvolúciós rétegeinek a típusában tér el. A sima egy dimenziós konvolúciós réteg helyett, egy dimenziós time-channel separable konvolúciós rétegeket használ \cite{quartznet}. Ennek a fő tulajdonsága, hogy jóval kevesebb paramétert használ az eredeti koncepciónál. Ennek köszönhetően mélyebb hálókat lehet készíteni nagyobb konvolúciós kernelekkel anélkül, hogy a a paraméterek száma, ezáltal a szükséges számítása kapacitás túlzottan megnövekedne.

\begin{figure}[!ht]
\centering
\includegraphics[width=150mm, keepaspectratio]{figures/QuartzNet-architecture.png}
\caption{QuartzNet architektúra. \cite{nemo}}
\end{figure}

\subsection{TensorBoard}

Az eredmények kiértékeléséhez és nyomon követéséhez a TensorBoard-ot, a TensorFlow egy vizualizációs toolkit-jét használtam. Több funkcióval is rendelkezik, mint például a súlyok időbeni változásának vizualizációja, illetve a tanítóadatok, képek, szöveg vagy hang anyag kijelzése. Számomra a legfontosabb tulajdonsága az egyes metrikák, a loss és a pontosság, a WER, értékének változásának nyomon követése.

A TensorBoard könnyedén indítható a következő parancs kiadásával: $tensorboard --logdir ~/lightning-logs$ , ahol a logdir kapcsoló adja meg melyik könyvtárban keressen TensorBoard kompatibilis log-okat, event-eket. A főkönyvtárban egyes almappáiban kell elhelyezni a tanítás során előállított event-eket, így a Tensorboard különálló tanításként ismeri fel őket. A szükséges event-ek előállítása könnyedén végezhető a NeMo toolkit segítségével, mely támogatja a megfelelő callback függvények használatát, amik az event-ek batch-enkénti frissítsét tesznek lehetővé. A callback függvény egyszerűen bővíthető szükség szerint.

\begin{figure}[!ht]
\centering
\includegraphics[width=150mm, keepaspectratio]{figures/tensorboard-example.png}
\caption{Lokálisan futtatott TensorBoard.}
\end{figure}

\section{Angol, majd orosz}

Kezdetben a tesztelést az egyik leggyakoribb nyelven, az angolon, végeztem. Ennek oka főként az volt, hogy megbizonyosodjak a modellem és a NeMo beállításainak sikerességéről, hogy megfelelő eredményeket tudok elérni elterjedt, kisebb adatbázisokon. Másfelől a modellem hiperparamétereit, mint például a learning rate, optimalizáltam, és az orosz nyelven történő kísérletezésnek a legbiztatóbb beállításokkal tudtam nekiállni.

Az angol nyelvű eredményeket viszonyításként is fel tudtam használni az végső orosz eredményekkel való összehasonlításánál, ahol a nagyságrendileg azonos mennyiségű orosz adatoknak az angoléhoz hasonló eredményeket kellett produkálniuk.

\subsection{Google Colab}

A NeMo-val való ismerkedéshez felhasználtam egy, az Nvidia által írt, jupyter notebook-ot\footnote{Tutorial notebook, \url{https://github.com/NVIDIA/NeMo/blob/main/tutorials/asr/01_ASR_with_NeMo.ipynb}}, melyet könnyedén és ingyenesen lehet Google Colab-ból\footnote{Google Colab, \url{https://colab.research.google.com/notebooks/intro.ipynb}} futtatni. A Colab ingyenes hozzáférést nyújt GPU erőforrásokhoz, ahol egyenesen a böngészőből futtatható a Python kód és az eredményeket akár le is lehet tölteni. Csupán be kell importálni a Colab környezetbe a github-on elérhető notebook-ot a az URL megadásával, majd tömbönként futtatható a kód, melyhez magyarázat is tartozik.

Sajnos a Colab bizonyos órán belül felfüggeszti a munkamenetet, illetve a nagy mennyiségű adatok munkamenetenkénti le- és feltöltése időigényes. Ezért főleg a kisebb, rövidebb adatbázisokon, mint például az AN4-en, lehetséges a kísérletezés és a toolkit-tel való ismerkedésen túl nem jelent megoldást.

\section{Adatbázisok}

A megfelelő modell megtalálásához két darab angol nyelvű adatbázist is használtam. Mikor elégedett voltam az eredményekkel és megbizonyosodtam, hogy sikeresen beállítottam a NeMo toolkit-et is, áttértem az orosz nyelvű modell fejlesztésére.

Az adatbázisokon belül három különböző típusú, egymástól független adathalmazt szükséges megállapítani. Az egyik a tanító adathalmaz, ezeket a hanganyagokat közvetlen a háló tanítására használjuk. Fontos, hogy legyen egy validációs vagy teszt adathalmaz is, amit tanítás közben használunk kiértékelésre, a tanítás általános pontosságának értékelésére. A harmadik dev adathalmaz pedig azért szükséges, mert a validációs adathalmaz pontosságát igyekszünk javítani, majd amikor ezzel elégedettek vagyunk egy tőle független adathalmazzal vizsgálhatjuk meg a végső pontosságot.

\subsection{Adatok előfeldolgozása}

Magukat a hangfájlokat is meg kell vizsgálni, egységesíteni kell a tanítás előtt. A leggyakrabban használt kiterjesztés a .wav, így én is ennek a használata mellett döntöttem. Szükség esetén az egyes hangfájlokat át kell konvertálni ebbe a formátumba a tanítás, kiértékelés előtt.

A hanganyagok megfelelő mintavételi frekvenciájának megválasztása fontos feladat. A túl alacsony mintavételezés minőségi romlást, rosszabb eredményeket okozhat, mivel a magasabb frekvenciakomponensek eldobásra kerülnek. A túl magas mintavételezés lassítja a tanítási folyamatot és akár szintén rosszabb eredményeket produkálhat.

Az adatbázisok esetén megvizsgálandó, hogy hány beszélő hangja található benne. Minél több van benne annál általánosabban alkalmazható jobb eredményekkel.

\subsection{AN4}

Az AN4\cite{an4} vagy "census" angol nyelvű beszéd adatbázist 1991-ben vették fel a Carnegie Mellon Egyetemen. A különböző beszélők betűzve mondanak olyan adatokat mint a születési dátumuk, telefonszámuk, a nevük vagy egyéb véletlenszerűen generált, előre definiált kontroll szavak.

Az adatbázis két különböző részre van osztva, az első a tanítást szolgálja, míg a második része a tesztelést. Ez előbbi 50 percnyi beszédet tartalmaz, míg a tesztelésre szolgáló rész 6 percet. Rövidségéből adódóan gyorsan tanítható és értékelhető, mely ideálissá teszi gyors kalibrálási, beállítási feladatok megoldására.

\subsection{LibriSpeech}

A LibriSpeech egy több száz órát tartalmazó, szintén angol nyelű, hangoskönyv gyűjtemény. Ez az egyik leginkább használt adatbázis, melyet előszeretettel alkalmaznak tudományos, kutatási munkák során, hálók tanításához és ezáltal az eredményeinek ismertetésekor.

Az elérhető hanganyag fele tiszta, könnyen érthető, míg másik fele zajosabb körülmények közt lett felvéve vagy kevésbé kivehető. Külön tartalmaz tanító, teszt és dev adathalmazokat. A tanításhoz a 100 órányi tiszta adathalmazt, a train-clean-100-at alkalmaztam.

\subsection{Mozilla Common Voice}

A Mozilla Common Voice\footnote{Mozilla Common Voice weboldala, \url{https://voice.mozilla.org/}} egy Mozilla által indított projekt. Célja, hogy különböző nyelveken, így oroszul is, a közösség erejét felhasználva gyűjtsön anonim hanganyagokat. Bárki felveheti a saját hangját, előre meghatározott szövegeket felolvasva, illetve érvényesíthet mások által felolvasott szövegeket. A biztonság és pontosság kedvéért egy szöveget két személynek is jóvá kell hagynia.

Orosz hangból durván 100 órányi áll rendelkezésre, de tüzetesebb vizsgálat után észrevettem, hogy ebből ~10-10 óra a teszt és dev adathalmaz mérete, míg ~20 óra a tanító adathalmazé. A maradék ~60 óra nagy része azért nincs használva, mert megismételt szöveget olvasnak fel benne, vagy rövid hanganyagokat tartalmaz. A tanító adathalmazt sikerült feldúsítsam ~45 óra környékére azáltal, hogy belevettem a 100 órányi hangból az összes olyan hangot, melyek nem voltak benne sem a teszt sem a dev adathalmazokban.

% insert random data analysis here?

\subsection{További orosz adatbázisok}

Mivel a Mozilla Common Voice orosz nyelvű adatbázisa legfeljebb 45 órányi tanítóadattal rendelkezik, míg a LibriSpeech-é mely eredményeihez viszonyítani szeretnénk 100 órán lett tanítva, ezért több tanítóadatot is be kellett vonni. Egy ingyenesen hozzáférhető github-on található projektben\footnote{Ingyenes orosz adatbázisok, \url{https://github.com/snakers4/open_stt/blob/master/README.md}} több adatbázis is található, többnyire .opus formátumban. Ezek közül elsősorban a "Radio2" adatbázissal dolgoztam.

Fontos megemlíteni a Mozzila Common Voice és egyéb rádiós műsorban elhangzott hanganyagok közötti lehetséges különbségeket. Míg előbbi többnyire bediktált, felolvasott szöveget tartalmaz különböző minőségben és tempóban, utóbbi kötetlenebb, tisztább minőségű beszélgetéseket is tartalmazhat.

\section{A tervezés eredményei}

Megoldásomban az Nvidia QuartzNet alapján indultam el, annak alacsony paraméterszámát figyelembe véve. Egy Pytorch alapú toolkit-et, az Nvidia NeMo-t (Neural Modules) használva kísérleteztem QuartzNet kombinációkkal.

Főként az ingyenesen hozzáférhető Mozilla Common Voice adatbázist használva tanítottam orosz nyelvre két architektúrájú modellt a 15x5 és a 12x1-et. A modellt véletlenszerűen beállított súlyokkal és transfer learning-et alkalmazva, egy előre tanított angol modellbeli súlyokkal inicializáltam. Az eredmény finomítása végett próbálkoztam több tanítóadat beiktatásával, mellyel a validációs adathalmaz WER értéke csökkenése, annak javítása volt a célom.

A 4.1-es táblázatban láthatóak a felhasznált adatbázisok, azok származási helye, fontosabb paraméterei és elnevezése a diplomamunkán belül.

\begin{table}[ht]
	\footnotesize
	\centering
	\begin{tabular}{ p{2cm} p{2cm} p{3cm} p{2cm} p{2.5cm} }
		\toprule
		\textbf{Elnevezés} & \textbf{Adatbázis Neve} & \textbf{Adatok hossza órában} & \textbf{Nyelv} & \textbf{Minőség} \\
		\midrule
		an4 & AN4 & 1 & angol & tiszta \\
		\hline
		LS100 & LibriSpeech & 100 & angol & tiszta \\
		\hline
		orosz\_rövid & Mozilla Common Voice & 19 & orosz & változó \\
		\hline
		orosz\_közepes &  Mozilla Common Voice & 45 & orosz & változó \\
		\hline
		orosz\_hosszú & Radio2 & 194 & orosz & tiszta \\
		\bottomrule
	\end{tabular}
	\caption{Felhasznált adatbázisok ismertetése és elnevezése.}
\end{table}